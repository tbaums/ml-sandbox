{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# COVID-19 mRNA Vaccine Degradation Prediction\n",
    "\n",
    "\n",
    "**Context: The most promising COVID-19 vaccine candidates use messenger RNA molecules (mRNA)** to help the patient develop immunity. Unfortunately, mRNA molecules are extremely fragile, and in certain circumstances spontaneously degrade. Current best scientific understanding lacks a means to analyze mRNA molecule candidates for areas of likely degradation.\n",
    "\n",
    "**Goal: Predict degradation rates for each part of an RNA molecule.**\n",
    "\n",
    "![mrna diagram](https://upload.wikimedia.org/wikipedia/commons/f/fb/MRNA-interaction.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Automated hyper-parameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pipeline-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "LR = 1e-3\n",
    "EPOCHS = 4\n",
    "BATCH_SIZE = 64\n",
    "EMBED_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "DROPOUT = .5\n",
    "SP_DROPOUT = .3\n",
    "TRAIN_SEQUENCE_LENGTH = 107"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:load_data"
    ]
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_json(\"data/train.json\", lines=True)\n",
    "test_df = pd.read_json(\"data/test.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_submission_df = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:preprocess_data",
     "prev:load_data"
    ]
   },
   "outputs": [],
   "source": [
    "symbols = \"().ACGUBEHIMSX\"\n",
    "feat_cols = [\"sequence\", \"structure\", \"predicted_loop_type\"]\n",
    "target_cols = [\"reactivity\", \"deg_Mg_pH10\", \"deg_Mg_50C\", \"deg_pH10\", \"deg_50C\"]\n",
    "error_cols = [\"reactivity_error\", \"deg_error_Mg_pH10\", \"deg_error_Mg_50C\", \"deg_error_pH10\", \"deg_error_50C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(char_level=True, filters=\"\")\n",
    "tokenizer.fit_on_texts(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the number of elements in the vocabulary\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_features(example):\n",
    "    sequence_sentences = example[0]\n",
    "    structure_sentences = example[1]\n",
    "    loop_sentences = example[2]\n",
    "    \n",
    "    # transform character sequences into number sequences\n",
    "    sequence_tokens = np.array(\n",
    "        tokenizer.texts_to_sequences(sequence_sentences)\n",
    "    )\n",
    "    structure_tokens = np.array(\n",
    "        tokenizer.texts_to_sequences(structure_sentences)\n",
    "    )\n",
    "    loop_tokens = np.array(\n",
    "        tokenizer.texts_to_sequences(loop_sentences)\n",
    "    )\n",
    "    \n",
    "    # concatenate the tokenized sequences\n",
    "    sequences = np.stack(\n",
    "        (sequence_tokens, structure_tokens, loop_tokens),\n",
    "        axis=1\n",
    "    )\n",
    "    sequences = np.transpose(sequences, (2, 0, 1))\n",
    "    \n",
    "    prepared = sequences.tolist()\n",
    "    \n",
    "    return prepared[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_labels(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    labels = np.array(df[target_cols].values.tolist())\n",
    "    labels = np.transpose(labels, (0, 2, 1))\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_test_df = test_df.query(\"seq_length == 107\")\n",
    "private_test_df = test_df.query(\"seq_length == 130\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train = [process_features(row.tolist()) for _, row in train_df[feat_cols].iterrows()]\n",
    "y_train = process_labels(train_df)\n",
    "\n",
    "unprocessed_x_public_test = [row.tolist() for _, row in public_test_df[feat_cols].iterrows()]\n",
    "unprocessed_x_private_test = [row.tolist() for _, row in private_test_df[feat_cols].iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:model_training",
     "prev:preprocess_data"
    ]
   },
   "outputs": [],
   "source": [
    "def gru_layer(hidden_dim, dropout):\n",
    "    return tf.keras.layers.Bidirectional(\n",
    "         tf.keras.layers.GRU(hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer = 'orthogonal')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lstm_layer(hidden_dim, dropout):\n",
    "    return tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer = 'orthogonal')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(vocab_size, seq_length=TRAIN_SEQUENCE_LENGTH, pred_len=68,\n",
    "                embed_dim=EMBED_DIM,\n",
    "                hidden_dim=HIDDEN_DIM, dropout=DROPOUT, sp_dropout=SP_DROPOUT):\n",
    "    inputs = tf.keras.layers.Input(shape=(seq_length, 3))\n",
    "\n",
    "    embed = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)(inputs)\n",
    "    \n",
    "    reshaped = tf.reshape(\n",
    "        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3])\n",
    "    )\n",
    "    \n",
    "    hidden = tf.keras.layers.SpatialDropout1D(sp_dropout)(reshaped)\n",
    "    \n",
    "    hidden = gru_layer(hidden_dim, dropout)(hidden)\n",
    "    hidden = lstm_layer(hidden_dim, dropout)(hidden)\n",
    "    \n",
    "    truncated = hidden[:, :pred_len]\n",
    "    \n",
    "    out = tf.keras.layers.Dense(5, activation=\"linear\")(truncated)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MeanColumnwiseRMSE(tf.keras.losses.Loss):\n",
    "    def __init__(self, name='MeanColumnwiseRMSE'):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n",
    "        return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(tf.optimizers.Adam(learning_rate=LR), loss=MeanColumnwiseRMSE())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(np.array(x_train), np.array(y_train), \n",
    "                    validation_split=.1, batch_size=BATCH_SIZE, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_loss = history.history.get(\"val_loss\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:model_evaluation",
     "prev:model_training"
    ]
   },
   "outputs": [],
   "source": [
    "model_public = build_model(vocab_size, seq_length=107, pred_len=107)\n",
    "model_private = build_model(vocab_size, seq_length=130, pred_len=130)\n",
    "\n",
    "model_public.set_weights(model.get_weights())\n",
    "model_private.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "block:"
    ]
   },
   "outputs": [],
   "source": [
    "public_preds = model_public.predict(np.array([process_features(x) for x in unprocessed_x_public_test]))\n",
    "private_preds = model_private.predict(np.array([process_features(x) for x in unprocessed_x_private_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "pipeline-metrics"
    ]
   },
   "outputs": [],
   "source": [
    "print(validation_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": true,
   "docker_image": "gcr.io/arrikto/jupyter-kale:4a5d7e63-9f74f267",
   "experiment": {
    "id": "new",
    "name": "vaccine-rna-degradation"
   },
   "experiment_name": "vaccine-rna-degradation",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 6,
    "objective": {
     "additionalMetricNames": [],
     "goal": 0,
     "objectiveMetricName": "validation-loss",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": [
     {
      "feasibleSpace": {
       "max": "0.01",
       "min": "0.0001",
       "step": "0.0003"
      },
      "name": "LR",
      "parameterType": "double"
     },
     {
      "feasibleSpace": {
       "max": "256",
       "min": "32",
       "step": "32"
      },
      "name": "BATCH_SIZE",
      "parameterType": "int"
     },
     {
      "feasibleSpace": {
       "max": "100",
       "min": "20",
       "step": "20"
      },
      "name": "EMBED_DIM",
      "parameterType": "int"
     },
     {
      "feasibleSpace": {
       "list": [
        "0.2",
        "0.3",
        "0.4",
        "0.5"
       ]
      },
      "name": "DROPOUT",
      "parameterType": "categorical"
     },
     {
      "feasibleSpace": {
       "list": [
        "0.2",
        "0.3",
        "0.4",
        "0.5"
       ]
      },
      "name": "SP_DROPOUT",
      "parameterType": "categorical"
     }
    ]
   },
   "katib_run": true,
   "pipeline_description": "predict mRNA base degredation",
   "pipeline_name": "vaccine-rna-degradation",
   "snapshot_volumes": true,
   "steps_defaults": [
    "label:access-ml-pipeline:true",
    "label:access-rok:true"
   ],
   "volumes": [
    {
     "annotations": [],
     "mount_point": "/home/jovyan",
     "name": "workspace-demo-da210qmer",
     "size": 5,
     "size_type": "Gi",
     "snapshot": false,
     "type": "clone"
    }
   ]
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}